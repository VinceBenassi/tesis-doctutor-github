{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traductor de idiomas hecho\n",
    "# con procesamiento de lenguaje\n",
    "# natural para DocTutor\n",
    "# por Franco Benassi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown, display, HTML as html_print   # Diseño de letras \n",
    "from spacy_langdetect import LanguageDetector\n",
    "from spacy.language import Language\n",
    "from googletrans import Translator # Librería para traducir la voz o texto de un idioma a otro\n",
    "from nltk.corpus import stopwords\n",
    "import speech_recognition as sr\n",
    "import pandas as pd\n",
    "import pyttsx3    # Librería para convertir texto a voz\n",
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar stopwords si no están disponibles\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords') \n",
    "except LookupError:\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones para inicializar Spacy\n",
    "def obtener_detector(nlp, name):\n",
    "    return LanguageDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo de lenguaje \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_langdetect.spacy_langdetect.LanguageDetector at 0x1822c3bd160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    Language.factory(\"language_detector\", func=obtener_detector)\n",
    "except Exception as e: \n",
    "    next\n",
    "nlp.add_pipe('language_detector', last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función para relacionar el texto traducido\n",
    "# con las palabras vacías definidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relacion_texto_palabras(lst1, lst2):\n",
    "    return set(lst1).intersection(lst2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones para imprimir mensajes a colores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cstr(s, color='black', size='50'):\n",
    "    return \"<text style='color:{}; font-size:{}px'>{}</text>\".format(color, size, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_color(t):\n",
    "    display(html_print(' '.join([cstr(ti, color=ci, size=si) for ti, ci, si in t])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializando variables\n",
    "grabador = sr.Recognizer()  # Grabar la voz\n",
    "grabador.energy_threshold = 300\n",
    "traductor_google = Translator() # iniciar traductor de google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el texto en una voz llamada juan\n",
    "convertidor_voz = pyttsx3.init()\n",
    "convertidor_voz.setProperty('rate', 200)\n",
    "convertidor_voz.setProperty('volume', 1)\n",
    "convertidor_voz.setProperty('voice', 'com.apple.speech.synthesis.voice.juan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar listas con algunas palabras vacías (stopwords)\n",
    "# que no son reconocidas por los robots de google y carecen de\n",
    "# sentido al usarlas solas. Ej: aún, ante, antes, en, y, etc. en\n",
    "# algunos idiomas diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_fr = stopwords.words('french')\n",
    "lista_pt = stopwords.words('portuguese')\n",
    "lista_es = stopwords.words('spanish')\n",
    "lista_en = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para reconocer el sonido\n",
    "def reconocer(sonido):\n",
    "    idiomas = ['fr-FR', 'pt-BR', 'es-ES', 'en-US']  # idiomas que se usaran para traducir un audio sin saber el idioma original\n",
    "    fr, pt, es, en = 0, 0, 0, 0\n",
    "\n",
    "    # Dataframe para \n",
    "    df = pd.DataFrame(columns = ['traductor_voz', 'idioma', 'valor', 'palabras', 'stopwords', 'idioma_final', 'match', 'nota'])\n",
    "    idioma_final = 'Ninguno'\n",
    "    \n",
    "    for elemento in idiomas:\n",
    "        try:\n",
    "            # traducir el audio recibido a los idiomas en cada elemento del arreglo de los idiomas\n",
    "            traductor_voz = grabador.recognize_google(sonido, language=elemento)\n",
    "            \n",
    "            # Descifrar con spacy que idioma es el del audio con la \n",
    "            # probabilidad de que el audio realmente es el idioma \n",
    "            # especificado por el descifrado\n",
    "            valor     = nlp(traductor_voz)._.language.get('score') \n",
    "            idioma    = nlp(traductor_voz)._.language.get('language') # devolver el nombre del idioma descifrado\n",
    "            palabras  = len(traductor_voz.split()) # contar la cantidad de palabras reconocidas del audio por la función\n",
    "            stopwords = 0\n",
    "\n",
    "            # Si se reconoce alguno de los idiomas, que se guarden las\n",
    "            # stopwords, el contador de cada idioma y en la función interseccion\n",
    "            # relacionar el texto al cual fue traducido la voz del usuario con cada\n",
    "            # arreglo con palabras de los siguientes idiomas para saber cuantas palabras \n",
    "            # en francés fueron reconocidas por la traducción y compararlas con cada arreglo\n",
    "            # de los idiomas\n",
    "            if idioma == 'fr': stopwords, fr, idioma_final = len(relacion_texto_palabras(traductor_voz.split(), lista_fr)), (fr+1), 'Frances'\n",
    "            if idioma == 'pt': stopwords, pt, idioma_final = len(relacion_texto_palabras(traductor_voz.split(), lista_pt)), (pt+1), 'Portugues'\n",
    "            if idioma == 'es': stopwords, es, idioma_final = len(relacion_texto_palabras(traductor_voz.split(), lista_es)), (es+1), 'Español'\n",
    "            if idioma == 'en': stopwords, en, idioma_final = len(relacion_texto_palabras(traductor_voz.split(), lista_en)), (en+1), 'Ingles'\n",
    "\n",
    "            # Guardar la información anterior en el dataframe sabiendo si el idioma de la voz usuario traducida\n",
    "            # y el traductor de spacy realmente detectó que el usuario estaba hablando en el idioma que detectó\n",
    "            # pasando en una fila del dataframe el texto traducido, el idioma, las palabras y demás.\n",
    "            if idioma == elemento[0:2]: df.loc[len(df)] = [traductor_voz, idioma, valor, palabras, stopwords, idioma_final, 0, 0.0]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            next\n",
    "    \n",
    "\n",
    "    # Recorrer el dataframe para generar los valores de las ultimas 2 columnas\n",
    "    # match y nota, donde match guardará cuantos idiomas de los establecidos\n",
    "    # detectaron el idioma con el que estaba hablando el usuario.\n",
    "    # el usuario buscó traducir su voz a 4 idiomas diferentes y match guardará\n",
    "    # cuantos idiomas detectaron que el usuario hablaba en el idioma que estaba\n",
    "    # hablando.\n",
    "    for index, row in df.iterrows():\n",
    "        # fr pregunta, cuantos idiomas detectaron que se habló en francés cuando el usuario bucaba traducir lo que estaba hablando?\n",
    "        if row['idioma']=='fr': df.at[index, 'match'] = fr \n",
    "        if row['idioma']=='pt': df.at[index, 'match'] = pt\n",
    "        if row['idioma']=='es': df.at[index, 'match'] = es\n",
    "        if row['idioma']=='en': df.at[index, 'match'] = en\n",
    "    \n",
    "    # La columna nota guardará una nota final de acuerdo a\n",
    "    # la cantidad de palabras que se reconocieron en el idioma\n",
    "    # más cuantos stopwords se detectaron en ese idioma por el\n",
    "    # porcentaje de acierto del idioma y por cuantas veces se\n",
    "    # encontró el acierto del idioma en los demás idiomas\n",
    "    df['nota'] = (df['palabras']+df['stopwords'])*df['valor']*df['match'] # valor es el % de que se acertó el idioma que hablaba el usuario\n",
    "    resultado = df[df['nota'] == df['nota'].max()] # ordenar por la mayor nota y generar un dataframe con una fila que tendrá la mayor nota\n",
    "    \n",
    "    # si no está vacío el dataframe anterior\n",
    "    # mostrar el idioma detectado por el traductor\n",
    "    # que se encuentra en la columna idioma_final\n",
    "    # en color azul y tamaño 40\n",
    "    if len(resultado) > 0:\n",
    "        print_color(((resultado['idioma_final'].values[0] + ' detectado', 'blue', '40'),))\n",
    "\n",
    "        return resultado['traductor_voz'].values[0]\n",
    "    else:\n",
    "        return 'Nada'  # si el resultado está vacío"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para escuchar el microfono\n",
    "def escuchar_microfono():\n",
    "    #Escuchamos el microfono\n",
    "    with sr.Microphone(device_index = 0) as source:\n",
    "        grabador.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        display_markdown('# Escuchando...', raw=True)\n",
    "        audio = grabador.listen(source, timeout=2)  # convertir la voz en un texto\n",
    "    \n",
    "    #Imprimimos el idioma identificado y traducido \n",
    "    try:\n",
    "        mensaje = reconocer(audio) # se pasa el audio a la función de reconocimiento de sonido para devolver un mensaje\n",
    "        print_color((('La persona dijo: ', 'blue', '35'), (mensaje, 'black', '30'))) # mostrar el mensaje por consola\n",
    "        \n",
    "        if mensaje != 'Nada':\n",
    "            texto_a_traducir = traductor_google.translate(mensaje, dest='es') # traducir el mensaje a español\n",
    "            texto = texto_a_traducir.text \n",
    "\n",
    "            print_color((('Traduccion: ', 'blue', '35'), (texto, 'black', '30')))\n",
    "            print(\"\\n\")\n",
    "\n",
    "            convertidor_voz.say(texto)  # pedir al traductor que hable la traducción\n",
    "            convertidor_voz.runAndWait()      \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"None\"\n",
    "\n",
    "    return mensaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Escuchando..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style='color:blue; font-size:40px'>Ingles detectado</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style='color:blue; font-size:35px'>La persona dijo: </text> <text style='color:black; font-size:30px'>why don't you think of Affairs this one</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style='color:blue; font-size:35px'>Traduccion: </text> <text style='color:black; font-size:30px'>¿Por qué no piensas en asuntos este?</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Escuchando..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style='color:blue; font-size:40px'>Ingles detectado</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style='color:blue; font-size:35px'>La persona dijo: </text> <text style='color:black; font-size:30px'>one to get the buffet this one</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style='color:blue; font-size:35px'>Traduccion: </text> <text style='color:black; font-size:30px'>uno para conseguir el buffet este</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Escuchando..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     traductor_voz \u001b[38;5;241m=\u001b[39m \u001b[43mescuchar_microfono\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m, in \u001b[0;36mescuchar_microfono\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     grabador\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m      6\u001b[0m     display_markdown(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m# Escuchando...\u001b[39m\u001b[38;5;124m'\u001b[39m, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mgrabador\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# convertir la voz en un texto\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#Imprimimos el idioma identificado y traducido \u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\benas\\Documents\\tutor-inteligente-tesis\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:491\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 491\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    493\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\benas\\Documents\\tutor-inteligente-tesis\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\benas\\Documents\\tutor-inteligente-tesis\\.venv\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    traductor_voz = escuchar_microfono()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
